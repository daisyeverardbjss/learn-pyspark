# Overview

This is a tutorial to try using the basics of pyspark to read a csv file into a dataframe and clean the data.

There are 2 options to set up this project. It can either be run locally or run on a databricks account. The recommended approach is to set this up on databricks

# Databricks setup

You may also run this lab by creating a databricks community edition account and using the notebooks provided in the `Databricks` directory. More detailed instructions can be found in the README there

# Local Setup

THIS DOESN'T WORK YET, PLEASE USE DATABRICKS VERSION

asdf
poetry
python version = 3.12

run `poetry init`
`poetry env use 3.12` will use python version 3.12
With the terminal open in this project, run `poetry install --no-root` to install all the depencies in the pyproject.toml file

Navigate to the Exercise 1 folder in the terminal and run the file task1.py with the command
use `poetry run python task1.py` to run the file
